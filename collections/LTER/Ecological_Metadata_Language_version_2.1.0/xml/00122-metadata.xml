<ns0:eml xmlns:ns0="eml://ecoinformatics.org/eml-2.1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" packageId="knb-lter-cap.284.10" system="ESRI MetaID" xsi:schemaLocation="eml://ecoinformatics.org/eml-2.1.0 http://data.gios.asu.edu/eml2_1_0/eml.xsd">
  <access authSystem="knb" order="allowFirst" scope="document">
    <allow>
      <principal>uid=CAP,o=LTER,dc=ecoinformatics,dc=org</principal>
      <permission>all</permission>
    </allow>
    <allow>
      <principal>public</principal>
      <permission>read</permission>
    </allow>
  </access>
  <dataset id="284_1" system="ESRI MetaID">
    <alternateIdentifier system="gios_dataset">284</alternateIdentifier>
    <shortName>vegetation_map_all_areas.img</shortName>
    <title>Plant survey of current vegetation of Sonoran desert plant community distribution in mountain parks in central Arizona-Phoenix, August 1999.</title>
    <creator>
      <individualName>
        <givenName>Arthur</givenName>
        <surName>Stiles</surName>
      </individualName>
      <organizationName>School of Life Sciences</organizationName>
      <address>
        <deliveryPoint>School of Life Sciences, Arizona State University, P.O. Box 874501, Tempe, AZ 85287, USA</deliveryPoint>
      </address>
    </creator>
    <pubDate>2005</pubDate>
    <language>en</language>
    <abstract>
      <para>This study represents an effort to map the distribution of plant community types
                across the Central Arizona - Phoenix Long Term Ecological Research (CAP-LTER) site
                centered in metropolitan Phoenix using Landsat ETM data. Vegetation classification
                was carried out using field data collected from within the study area describing
                woody plant species. A system was devised which represented a compromise between
                providing floristic information and enabling maximum spectral discrimination between
                community types. Image classification used reference spectra derived from training
                sites in the field and was carried out on subsets defined by soil surface texture in
                order to control for the strong background soil signature inherent to arid regions.
                While groundtruthing revealed that vegetation on clayey soils was mapped to 91%
                accuracy, other sections produced maps with less accuracy. The results of this study
                demonstrate that image classification of desert vegetation using only Landsat ETM
                data is problematic and may not be practical without other supporting data, such as
                radar imaging.</para>
    </abstract><keywordSet><keyword keywordType="theme">human decisions and biodiversity</keyword><keyword keywordType="theme">primary production</keyword><keyword keywordType="theme">population studies</keyword><keywordThesaurus>IPA and Core Area CAP Data Portal Controler</keywordThesaurus></keywordSet><keywordSet><keyword keywordType="place">sonoran desert</keyword><keyword keywordType="place">phoenix</keyword><keyword keywordType="theme">urban</keyword><keyword keywordType="theme">metropolitan area</keyword><keyword keywordType="theme">gis</keyword><keyword keywordType="theme">plants</keyword><keyword keywordType="theme">vegetation</keyword><keyword keywordType="theme">remote sensing</keyword><keyword keywordType="theme">landsat</keyword><keyword keywordType="theme">classification</keyword><keywordThesaurus>Creator Defined Keyword Set</keywordThesaurus></keywordSet><keywordSet><keyword keywordType="theme">urban</keyword><keyword keywordType="theme">maps</keyword><keyword keywordType="theme">deserts</keyword><keyword keywordType="theme">surveys</keyword><keyword keywordType="theme">plants</keyword><keyword keywordType="theme">vegetation</keyword><keyword keywordType="theme">communities</keyword><keyword keywordType="theme">soil</keyword><keyword keywordType="theme">landsat</keyword><keyword keywordType="theme">reflectance</keyword><keywordThesaurus>LTER Controlled Vocabulary Keyword Set</keywordThesaurus></keywordSet><keywordSet><keyword keywordType="theme">caplter</keyword><keyword keywordType="theme">central arizona phoenix longterm ecological research</keyword><keyword keywordType="place">arizona</keyword><keyword keywordType="theme">caplter created</keyword><keyword keywordType="place">az</keyword><keyword keywordType="theme">cap</keyword><keyword keywordType="theme">arid land</keyword><keywordThesaurus>CAPLTER Keyword Set List</keywordThesaurus></keywordSet>
    
    
    
    <intellectualRights>
      <section>
        <para>Copyright Board of Regents, Arizona State University. This dataset is released
                    to the public and may be used for academic, educational, or commercial purposes
                    subject to the following restrictions:</para>
        <para>
          <itemizedlist>
            <listitem>
              <para>While CAP LTER will make every effort possible to control and
                                document the quality of the data it publishes, the data are made
                                available "as is".</para>
            </listitem>
            <listitem>
              <para>CAP LTER cannot assume responsibility for damages resulting from
                                mis-use or mis-interpretation of datasets or from errors or
                                omissions that may exist in the data.</para>
            </listitem>
            <listitem>
              <para>It is considered a matter of professional ethics to acknowledge
                                the work of other scientists that has resulted in data used in
                                subsequent research.</para>
            </listitem>
            <listitem>
              <para>CAP LTER expects that any use of data from this server will be
                                accompanied with the appropriate citations and
                                acknowledgments.</para>
            </listitem>
            <listitem>
              <para>CAP LTER encourages users to contact the original investigator
                                responsible for the data that they are accessing. Where appropriate,
                                researchers whose projects are integrally dependent on CAP LTER data
                                are encouraged to consider collaboration and/or co-authorship with
                                original investigators.</para>
            </listitem>
            <listitem>
              <para>CAP LTER requests that users submit to the Global Institute of
                                Sustainability, ASU, one copy of any publication resulting from the
                                use of data obtained from this site.</para>
            </listitem>
            <listitem>
              <para>CAP LTER requests that users not redistribute data obtained from
                                this site. However, links or references to this site may be freely
                                posted.</para>
            </listitem>
          </itemizedlist>
        </para>
      </section>
    </intellectualRights>
    <distribution>
      <online>
        <url>http://data.gios.asu.edu/cap/HarvestListFileShow.php?id=284</url>
      </online>
    </distribution>
    <coverage>
      <temporalCoverage>
        <singleDateTime>
          <calendarDate>1999-08-01</calendarDate>
        </singleDateTime>
      </temporalCoverage>
      <geographicCoverage>
        <geographicDescription>Central Arizona Phoenix</geographicDescription>
        <boundingCoordinates>
          <westBoundingCoordinate>-112.631314</westBoundingCoordinate>
          <eastBoundingCoordinate>-111.925247</eastBoundingCoordinate>
          <northBoundingCoordinate>33.654583</northBoundingCoordinate>
          <southBoundingCoordinate>33.287300</southBoundingCoordinate>
        </boundingCoordinates>
      </geographicCoverage>
    </coverage>
    <purpose>
      <para>This project attempts to produce a vegetation distribution map across undeveloped
                parcels of outlying desert wilderness, as well as remnant mountain parks throughout
                the city, contained within the Central Arizona Phoenix Long Term Ecological Research
                (CAPLTER) study area. This effort seeks to create the first successful
                classification map of Sonoran Desert vegetation derived from satellite imagery. The
                map would also be the first fine-scale map of plant community types in the Phoenix
                region. The depiction would allow for a calculation of the land area covered by each
                vegetation class, and which communities are exposed to development pressures. This
                map potentially provides a basis from which researchers can measure vegetative
                biomass distribution across the landscape and attempt to incorporate this component
                into ecological models of energy flows and biogeochemical cycling in the CAP-LTER
                site. Information on vegetation location can also assist with sampling
                stratification in other research projects. Finally, this map would provide a
                valuable basis from which future changes in vegetation distribution can be
                assessed</para>
    </purpose>
    <maintenance>
      <description>
        <para>This research has been concluded</para>
      </description>
      <maintenanceUpdateFrequency>asNeeded</maintenanceUpdateFrequency>
    </maintenance>
    <contact id="Datamanager">
      <positionName>Information Manager</positionName>
      <address>
        <deliveryPoint>Global Institute of Sustainability</deliveryPoint>
        <deliveryPoint>Arizona State University</deliveryPoint>
        <deliveryPoint>POB 875402</deliveryPoint>
        <city>TEMPE</city>
        <administrativeArea>AZ</administrativeArea>
        <postalCode>85287-5402</postalCode>
        <country>USA</country>
      </address>
      <phone phonetype="voice">(480) 965 2975</phone>
      <phone phonetype="fax">(480) 965-8087</phone>
      <electronicMailAddress>caplter.data@asu.edu</electronicMailAddress>
    </contact>
    <methods>
      <methodStep>
        <description>
          <section>
            <title>Image prosessing and supervised classification</title>
            <para>The image was processed and analyzed using ERDAS Imagine software.
                            Prior to image classification, all ground cover features not associated
                            with undeveloped desert land were extracted from the scene. This
                            includes all impervious and landscaped surfaces associated with urban
                            areas and exposed soil related to industrial sites, clearings for new
                            urban development, and major disturbances (Ward et al. 2000). A
                            LANDISCOR color aerial photograph (2000) covering the study area was
                            used as an interpretive guide for ground features in order to aid in
                            extraction of urban features. A supervised classification procedure was
                            used in order to assign vegetation classes to the image pixels. This
                            method involves creation of spectral signatures for each candidate class
                            based on training sites in the field, which contain vegetation
                            indicative for each class. These class signatures are used as a
                            reference tool for the assigning of community types to pixels according
                            to maximum likelihood</para>
          </section>
          <section>
            <title>Field data collection</title>
            <para>A pilot study, which used field sampling locations used in the
                            TWINSPAN classification as training sites, yielded poor results, so
                            several corrective actions were instituted in order to increase
                            accuracy. Given the area of pixels (900 m2), the original field sample
                            plots were too small to use as training sites without significant risk
                            of contamination by other community types. Therefore, a separate effort
                            was made to collect training samples of each vegetation type over an
                            area encompassing multiple pixels, which were recorded on GPS and
                            designated during the training process. Since these samples formed the
                            reference source for all vegetation in the study area, each training
                            site was selected as an unambiguous representative of a given community
                            type. Multiple training sites, scattered across the landscape as much as
                            possible, were used for each reference signature. Whenever possible, a
                            minimum set of pixels equal to ten times the number of bands used, 70 in
                            this case, was utilized in order to create reference spectra, as
                            recommended by Congalton (1991).</para>
          </section>
          <section>
            <title>Auxiliary data</title>
            <para>The larger-scale thermal band 6, which has a resolution of 120 m
                            rather than 30 m inherent to the other bands, was dropped and replaced
                            with a Soil Adjusted Vegetation Index (SAVI) layer calculated from the
                            Landsat image. SAVI is a modification of the Normalized Difference
                            Vegetation Index (NDVI), which is commonly used to detect
                            photosynthetically active vegetation by virtue of relatively high
                            reflectance of near-infrared and low reflectance of visible red light.
                            SAVI includes a correction for soil reflectance, which is especially
                            useful given deserts&#226;&#8364;&#8482; high exposed soil coverage. Efforts were made to
                            make the soil substrate in each round of image classification as
                            constant as practical so that the vegetation would be the dissimilar
                            variable between pixels. Soil texture influences the scattering of
                            incident light so that larger particle soils provide more surfaces off
                            which light can reflect. GIS-based soil maps were obtained from the
                            Natural Resources Conservation Service, a division of the US Department
                            of Agriculture (Soil Survey Geographic [SSURGO] database 2002). These
                            maps were used to divide the total study area into sections based on
                            texture characteristics: sandy, loamy, clayey, and coarse particle
                            soils. An additional unlabeled class, roughly coinciding with the
                            shallow bedrock of mountainous areas, was divided further into sections
                            consisting of continuous patches for individualized treatment. The
                            intention of this step was to conglomerate sites with similar
                            reflectance features for a common classification effort. Each separate
                            patch was analyzed using unsupervised classification into eight classes.
                            In unsupervised classification, reference spectra are not determined by
                            the user; rather, the classifier groups pixels based on spectral
                            similarity inherent to the image itself with only the total number of
                            classes selected by the user. A GIS layer depicting local geology was
                            utilized in order to visually ascertain correspondence between
                            geological formations and the image classification. If there was a
                            correlation, the candidate area was split into separate parts; if there
                            was no correlation, the patch was retained whole. Next, separate patches
                            judged to be relatively self-similar were combined into a common view,
                            the classification was repeated, and similar areas were aggregated. This
                            process resulted in seven different study sections, each of which was
                            classified on its own with reference spectra derived from training sites
                            located within each section, if possible. If a hypothesized vegetation
                            type was not located during the training process, a signature from
                            another section was used, though this was necessary only a few
                            times.</para>
          </section>
          <section>
            <title>Accuracy assessment</title>
            <para>A random subset of these points was chosen to be surveyed in the
                            field. Registration of Landsat pixels is not perfect; image
                            rectification and restoration from raw data necessarily distorts actual
                            positioning of pixels to a slight degree. For this reason, points were
                            designated from clusters of similarly classed pixels. Coordinates were
                            chosen from each image section, which allowed for a separate accuracy
                            assessment for each section&#226;&#8364;&#8482;s classification. Vegetation within a 20 m
                            radius was surveyed to determine the appropriate community type. Since
                            the pixel array represents a two-dimensional depiction of the landscape,
                            training site radius was lengthened on slopes to allow for a horizontal
                            distance of 20 m. Post-groundtruthing procedures were used in order to
                            maximize accuracy, including refinement of training areas, deletion of
                            classes found to be absent or rare in each study section, and
                            aggregation of classes lacking strong discrimination according to
                            groundtruthing results, followed by reclassification of the scene.
                            Accuracy assessment was reported using an error matrix (Congalton and
                            Green 1999). Overall accuracy is a holistic summary of how successful
                            predicted class membership agreed with field observations from the
                            groundtruthing effort, and is calculated as the sum of the diagonal
                            cells divided by the total survey sites used to assess that particular
                            classification. Producer&#226;&#8364;&#8482;s accuracy demonstrates how well survey site
                            pixels of a particular vegetation type are classified, and equals the
                            number of correctly classified sites divided by the total number of
                            survey sites for that type, the column total (Lillesand and Kiefer
                            2000). User&#226;&#8364;&#8482;s accuracy represents the probability that a classified
                            pixel indicates the correct vegetation type in the field, and equals the
                            number of correctly classified sites divided by the total number of
                            sites that actually belong to that class, the row total. Since accuracy
                            assessment was not feasible for the more remote or inaccessible
                            locations of the Sierra Estrella Mountains, the McDowell Mountains, and
                            the sandy soil of the Hassayampa River, these areas were not
                            conducted.</para>
          </section>
        </description>
        <dataSource>
          <title>Landsat Thematic Mapper Imagery, 1999</title>
          <creator>
            <organizationName>NASA</organizationName>
          </creator>
          <contact>
            <individualName>
              <givenName>Chris</givenName>
              <surName>Eisinger</surName>
            </individualName>
            <organizationName>Geological Remote Sensing Laboratory , Geological
                            Sciences</organizationName>
            <address>
              <deliveryPoint>Mars Global Surveyor Space Flight Facility</deliveryPoint>
              <deliveryPoint>Arizona State University, TempeAZ 85287-1404</deliveryPoint>
              <city>Tempe</city>
            </address>
          </contact>
        </dataSource>
        <dataSource>
          <title>Soil Survey Geographic [SSURGO] database, 2002</title>
          <creator>
            <organizationName>US Department of Agriculture</organizationName>
          </creator>
          <contact>
            <organizationName>National Cartography and Geospatial
                            Center</organizationName>
            <address>
              <deliveryPoint>Fort Worth Federal Center</deliveryPoint>
              <deliveryPoint>501 West Felix Street, Building 23, P.O. Box 6567, Fort Worth, TX 76115</deliveryPoint>
              <city>Fort Worth</city>
            </address>
          </contact>
        </dataSource>
      </methodStep>
    </methods>
    <spatialRaster id="PlantSurvey_MtParks_2005">
      <entityName>PlantSurvey_MtParks_2005</entityName>
      <physical>
        <objectName>PlantSurvey_MtParks_2005</objectName>
        <dataFormat>
          <externallyDefinedFormat>
            <formatName>Raster Dataset</formatName>
          </externallyDefinedFormat>
        </dataFormat>
        <distribution>
          <online>
            <url>http://data.gios.asu.edu/datasets/cap/284.zip</url>
          </online>
        </distribution>
      </physical>
      <attributeList>
        <attribute id="ObjectID">
          <attributeName>ObjectID</attributeName>
          <attributeDefinition>Internal feature number.</attributeDefinition>
          <storageType typeSystem="http://www.esri.com/metadata/esriprof80.html">OID</storageType>
          <measurementScale>
            <nominal>
              <nonNumericDomain>
                <textDomain>
                  <definition>Sequential unique whole numbers that are
                                        automatically generated.</definition>
                </textDomain>
              </nonNumericDomain>
            </nominal>
          </measurementScale>
        </attribute>
        <attribute id="Value">
          <attributeName>Value</attributeName>
          <attributeDefinition>Class Code</attributeDefinition>
          <storageType typeSystem="http://www.esri.com/metadata/esriprof80.html">Integer</storageType>
          <measurementScale>
            <ratio>
              <unit>
                <standardUnit>number</standardUnit>
              </unit>
              <precision>1</precision>
              <numericDomain>
                <numberType>integer</numberType>
              </numericDomain>
            </ratio>
          </measurementScale>
        </attribute>
        <attribute id="Red">
          <attributeName>Red</attributeName>
          <attributeDefinition>Red</attributeDefinition>
          <storageType typeSystem="http://www.esri.com/metadata/esriprof80.html">Double</storageType>
          <measurementScale>
            <ratio>
              <unit>
                <standardUnit>number</standardUnit>
              </unit>
              <precision>1</precision>
              <numericDomain>
                <numberType>real</numberType>
              </numericDomain>
            </ratio>
          </measurementScale>
        </attribute>
        <attribute id="Green">
          <attributeName>Green</attributeName>
          <attributeDefinition>Green</attributeDefinition>
          <storageType typeSystem="http://www.esri.com/metadata/esriprof80.html">Double</storageType>
          <measurementScale>
            <ratio>
              <unit>
                <standardUnit>number</standardUnit>
              </unit>
              <precision>1</precision>
              <numericDomain>
                <numberType>real</numberType>
              </numericDomain>
            </ratio>
          </measurementScale>
        </attribute>
        <attribute id="Blue">
          <attributeName>Blue</attributeName>
          <attributeDefinition>Blue</attributeDefinition>
          <storageType typeSystem="http://www.esri.com/metadata/esriprof80.html">Double</storageType>
          <measurementScale>
            <ratio>
              <unit>
                <standardUnit>number</standardUnit>
              </unit>
              <precision>1</precision>
              <numericDomain>
                <numberType>real</numberType>
              </numericDomain>
            </ratio>
          </measurementScale>
        </attribute>
        <attribute id="Opacity">
          <attributeName>Opacity</attributeName>
          <attributeDefinition>Opacity</attributeDefinition>
          <storageType typeSystem="http://www.esri.com/metadata/esriprof80.html">Double</storageType>
          <measurementScale>
            <ratio>
              <unit>
                <standardUnit>number</standardUnit>
              </unit>
              <precision>1</precision>
              <numericDomain>
                <numberType>integer</numberType>
              </numericDomain>
            </ratio>
          </measurementScale>
        </attribute>
        <attribute id="Class_names">
          <attributeName>Class_names</attributeName>
          <attributeDefinition>Class_names</attributeDefinition>
          <storageType typeSystem="http://www.w3.org/2001/XMLSchema-datatypes">string</storageType>
          <measurementScale>
            <nominal>
              <nonNumericDomain>
                <enumeratedDomain>
                  <codeDefinition>
                    <code>Unclassified</code>
                    <definition>Unclassified</definition>
                  </codeDefinition>
                  <codeDefinition>
                    <code>Ambrosia Dom.</code>
                    <definition>Ambrosia Dominated</definition>
                  </codeDefinition>
                  <codeDefinition>
                    <code>Encelia Dom.</code>
                    <definition>Encelia Dominated</definition>
                  </codeDefinition>
                  <codeDefinition>
                    <code>Larrea Dom.</code>
                    <definition>Larrea Dominated</definition>
                  </codeDefinition>
                  <codeDefinition>
                    <code>Mixed scrub</code>
                    <definition>Mixed scrub</definition>
                  </codeDefinition>
                </enumeratedDomain>
              </nonNumericDomain>
            </nominal>
          </measurementScale>
        </attribute>
        <attribute id="Count">
          <attributeName>Count</attributeName>
          <attributeDefinition>Pixels counts for each class</attributeDefinition>
          <storageType typeSystem="http://www.esri.com/metadata/esriprof80.html">Double</storageType>
          <measurementScale>
            <ratio>
              <unit>
                <standardUnit>number</standardUnit>
              </unit>
              <precision>1</precision>
              <numericDomain>
                <numberType>whole</numberType>
              </numericDomain>
            </ratio>
          </measurementScale>
        </attribute>
      </attributeList>
      <spatialReference>
        <horizCoordSysName>WGS_1984_UTM_Zone_12N</horizCoordSysName>
      </spatialReference>
      <horizontalAccuracy>
        <accuracyReport>0.5-1 pixel</accuracyReport>
      </horizontalAccuracy>
      <verticalAccuracy>
        <accuracyReport>not reported</accuracyReport>
      </verticalAccuracy>
      <cellSizeXDirection>30.000000</cellSizeXDirection>
      <cellSizeYDirection>30.000000</cellSizeYDirection>
      <numberOfBands>1</numberOfBands>
      <rasterOrigin>Upper Left</rasterOrigin>
      <rows>1331</rows>
      <columns>2171</columns>
      <verticals>1</verticals>
      <cellGeometry>pixel</cellGeometry>
    </spatialRaster>
  </dataset>
</ns0:eml>